{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "This is the Colab notebook for the implementation of Object Proposals and Calculating Intersection of Unions (IoU). This code run for general classes and labels and not pertaining to our dataset. "
      ],
      "metadata": {
        "id": "bIiySKnJffiu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### *This code is from chatGPT*"
      ],
      "metadata": {
        "id": "yjTCkr5RiLU1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 1: Install the necessary libraries such as PyTorch, Torchvision, and Detectron2.\n",
        "\n",
        "First, we import the necessary libraries such as PyTorch, Torchvision, and Detectron2.\n",
        "\n"
      ],
      "metadata": {
        "id": "SZfKa92ShCwl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "7lXMC54d0FPG",
        "outputId": "ee1440a2-5f5d-4f30-dc9e-62d553114cdf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.8/dist-packages (1.13.1+cu116)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.8/dist-packages (0.14.1+cu116)\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement detectron2 (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for detectron2\u001b[0m\u001b[31m\n",
            "\u001b[0mLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/facebookresearch/detectron2\n",
            "  Cloning https://github.com/facebookresearch/detectron2 to /tmp/pip-req-build-oy4xy85b\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/facebookresearch/detectron2 /tmp/pip-req-build-oy4xy85b\n",
            "  Resolved https://github.com/facebookresearch/detectron2 to commit 670b54e376d468958834bce380672d5a23d49922\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: Pillow>=7.1 in /usr/local/lib/python3.8/dist-packages (from detectron2==0.6) (8.4.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (from detectron2==0.6) (3.5.3)\n",
            "Requirement already satisfied: pycocotools>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from detectron2==0.6) (2.0.6)\n",
            "Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.8/dist-packages (from detectron2==0.6) (2.2.0)\n",
            "Collecting yacs>=0.1.8\n",
            "  Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.8/dist-packages (from detectron2==0.6) (0.8.10)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.8/dist-packages (from detectron2==0.6) (2.2.1)\n",
            "Requirement already satisfied: tqdm>4.29.0 in /usr/local/lib/python3.8/dist-packages (from detectron2==0.6) (4.64.1)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.8/dist-packages (from detectron2==0.6) (2.11.2)\n",
            "Collecting fvcore<0.1.6,>=0.1.5\n",
            "  Downloading fvcore-0.1.5.post20221221.tar.gz (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.2/50.2 KB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting iopath<0.1.10,>=0.1.7\n",
            "  Downloading iopath-0.1.9-py3-none-any.whl (27 kB)\n",
            "Collecting omegaconf>=2.1\n",
            "  Downloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 KB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting hydra-core>=1.1\n",
            "  Downloading hydra_core-1.3.2-py3-none-any.whl (154 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.5/154.5 KB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting black\n",
            "  Downloading black-23.1.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m43.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from detectron2==0.6) (23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from fvcore<0.1.6,>=0.1.5->detectron2==0.6) (1.22.4)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from fvcore<0.1.6,>=0.1.5->detectron2==0.6) (6.0)\n",
            "Collecting antlr4-python3-runtime==4.9.*\n",
            "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 KB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.8/dist-packages (from hydra-core>=1.1->detectron2==0.6) (5.12.0)\n",
            "Collecting portalocker\n",
            "  Downloading portalocker-2.7.0-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->detectron2==0.6) (1.4.4)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib->detectron2==0.6) (0.11.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.8/dist-packages (from matplotlib->detectron2==0.6) (2.8.2)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib->detectron2==0.6) (4.38.0)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->detectron2==0.6) (3.0.9)\n",
            "Collecting mypy-extensions>=0.4.3\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Collecting pathspec>=0.9.0\n",
            "  Downloading pathspec-0.11.0-py3-none-any.whl (29 kB)\n",
            "Requirement already satisfied: typing-extensions>=3.10.0.0 in /usr/local/lib/python3.8/dist-packages (from black->detectron2==0.6) (4.5.0)\n",
            "Requirement already satisfied: platformdirs>=2 in /usr/local/lib/python3.8/dist-packages (from black->detectron2==0.6) (3.0.0)\n",
            "Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from black->detectron2==0.6) (2.0.1)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.8/dist-packages (from black->detectron2==0.6) (8.1.3)\n",
            "Requirement already satisfied: protobuf<4,>=3.9.2 in /usr/local/lib/python3.8/dist-packages (from tensorboard->detectron2==0.6) (3.19.6)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard->detectron2==0.6) (2.16.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard->detectron2==0.6) (57.4.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard->detectron2==0.6) (3.4.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard->detectron2==0.6) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard->detectron2==0.6) (2.2.3)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard->detectron2==0.6) (0.6.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard->detectron2==0.6) (0.4.6)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.8/dist-packages (from tensorboard->detectron2==0.6) (0.38.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard->detectron2==0.6) (2.25.1)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard->detectron2==0.6) (1.51.3)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.8/dist-packages (from tensorboard->detectron2==0.6) (1.4.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard->detectron2==0.6) (1.15.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard->detectron2==0.6) (0.2.8)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard->detectron2==0.6) (5.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard->detectron2==0.6) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->detectron2==0.6) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard->detectron2==0.6) (6.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.6) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.6) (2022.12.7)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.6) (4.0.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.6) (1.26.14)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.8/dist-packages (from werkzeug>=1.0.1->tensorboard->detectron2==0.6) (2.1.2)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.8/dist-packages (from importlib-resources->hydra-core>=1.1->detectron2==0.6) (3.15.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->detectron2==0.6) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->detectron2==0.6) (3.2.2)\n",
            "Building wheels for collected packages: detectron2, fvcore, antlr4-python3-runtime\n",
            "  Building wheel for detectron2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for detectron2: filename=detectron2-0.6-cp38-cp38-linux_x86_64.whl size=6410967 sha256=139c92861ff76c1f6bc629c4e40f9130eb35b0ff03622e0c211c6fcbaa3c8e7b\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-z8q_aic5/wheels/12/7a/54/bdd5b82ce522ace85e50e6348a49d0cc452d47cba11657e0bb\n",
            "  Building wheel for fvcore (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fvcore: filename=fvcore-0.1.5.post20221221-py3-none-any.whl size=61431 sha256=155a151bec72c0f29c46128c70e063b06c3f0a8c5cbd6e1b6e3010c959e973d5\n",
            "  Stored in directory: /root/.cache/pip/wheels/b8/79/07/c0e9367f5b5ea325e246bd73651e8af175fabbef943043b1cc\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144575 sha256=aa7a9dad416375e6e56d0d97aa513973c73a3302524e0a0d580604185d78a0bf\n",
            "  Stored in directory: /root/.cache/pip/wheels/b1/a3/c2/6df046c09459b73cc9bb6c4401b0be6c47048baf9a1617c485\n",
            "Successfully built detectron2 fvcore antlr4-python3-runtime\n",
            "Installing collected packages: antlr4-python3-runtime, yacs, portalocker, pathspec, omegaconf, mypy-extensions, iopath, hydra-core, black, fvcore, detectron2\n",
            "Successfully installed antlr4-python3-runtime-4.9.3 black-23.1.0 detectron2-0.6 fvcore-0.1.5.post20221221 hydra-core-1.3.2 iopath-0.1.9 mypy-extensions-1.0.0 omegaconf-2.3.0 pathspec-0.11.0 portalocker-2.7.0 yacs-0.1.8\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pydevd_plugins"
                ]
              }
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install torch torchvision detectron2\n",
        "!pip install git+https://github.com/facebookresearch/detectron2"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 2: Import the required libraries\n",
        "Next, we load the pre-trained Mask R-CNN model for instance segmentation from the Detectron2 model zoo. We use the \"get_cfg\" function to obtain the configuration for the model specified by its name, merge the default configuration with the model configuration, set a threshold for the model's prediction scores, and load the pre-trained weights. We then create a predictor object using this configuration."
      ],
      "metadata": {
        "id": "XoiosSVyg932"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import numpy as np\n",
        "import cv2\n",
        "import detectron2\n",
        "from detectron2.utils.logger import setup_logger\n",
        "from detectron2 import model_zoo\n",
        "from detectron2.engine import DefaultPredictor\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2.data import MetadataCatalog\n",
        "from detectron2.utils.visualizer import Visualizer,VisImage\n",
        "from detectron2.structures import BoxMode\n"
      ],
      "metadata": {
        "id": "kx8L74rc0Irc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 3: Load the pre-trained model using Detectron2\n",
        "We load an input image using the \"cv2.imread\" function, which returns a numpy array representation of the image."
      ],
      "metadata": {
        "id": "rtX85uA9hJzm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = \"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"\n",
        "cfg = get_cfg()\n",
        "cfg.merge_from_file(model_zoo.get_config_file(model))\n",
        "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5  # set threshold for this model\n",
        "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(model)\n",
        "predictor = DefaultPredictor(cfg)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R2YECwzU0IuS",
        "outputId": "bf876a04-bd8a-4290-d7c4-6ad740bbd2a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "model_final_f10217.pkl: 178MB [00:02, 86.0MB/s]                          \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 4: Load the image and make a prediction using the pre-trained model\n",
        "\n",
        "We pass this input image through the Mask R-CNN model using the predictor object we created earlier. This gives us the model's predictions for the input image, which includes the predicted bounding boxes and class labels for the objects in the image. You can change the image path as per your needs."
      ],
      "metadata": {
        "id": "gw70k4fVhPMF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "im = cv2.imread(\"/content/operating-room.jpg\")\n",
        "outputs = predictor(im)\n"
      ],
      "metadata": {
        "id": "A47DshXV0Iw7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "561236c7-7391-4ff8-ff4a-6fd484f680da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 5: Extract the bounding box coordinates and class labels from the prediction\n",
        "\n",
        "We extract the predicted bounding box coordinates and class labels from the model's predictions using the \"pred_boxes\" and \"pred_classes\" attributes of the \"outputs[\"instances\"]\" object returned by the predictor."
      ],
      "metadata": {
        "id": "G9Tx3Zk5ha2V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pred_classes = outputs[\"instances\"].pred_classes.tolist()\n",
        "pred_boxes = outputs[\"instances\"].pred_boxes.tensor.tolist()\n"
      ],
      "metadata": {
        "id": "28Rlf4ab0Izv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(outputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mbpVPNi5Czqn",
        "outputId": "bad63534-ec79-4398-9b8f-29aa900caf65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'instances': Instances(num_instances=3, image_height=650, image_width=1000, fields=[pred_boxes: Boxes(tensor([[ 463.2617,  231.3715,  519.5033,  278.9182],\n",
            "        [ 295.2306,  412.6859,  382.3875,  508.3141],\n",
            "        [ 924.3395,  341.4202, 1000.0000,  581.0680]], device='cuda:0')), scores: tensor([0.9174, 0.7018, 0.5236], device='cuda:0'), pred_classes: tensor([62, 56, 68], device='cuda:0'), pred_masks: tensor([[[False, False, False,  ..., False, False, False],\n",
            "         [False, False, False,  ..., False, False, False],\n",
            "         [False, False, False,  ..., False, False, False],\n",
            "         ...,\n",
            "         [False, False, False,  ..., False, False, False],\n",
            "         [False, False, False,  ..., False, False, False],\n",
            "         [False, False, False,  ..., False, False, False]],\n",
            "\n",
            "        [[False, False, False,  ..., False, False, False],\n",
            "         [False, False, False,  ..., False, False, False],\n",
            "         [False, False, False,  ..., False, False, False],\n",
            "         ...,\n",
            "         [False, False, False,  ..., False, False, False],\n",
            "         [False, False, False,  ..., False, False, False],\n",
            "         [False, False, False,  ..., False, False, False]],\n",
            "\n",
            "        [[False, False, False,  ..., False, False, False],\n",
            "         [False, False, False,  ..., False, False, False],\n",
            "         [False, False, False,  ..., False, False, False],\n",
            "         ...,\n",
            "         [False, False, False,  ..., False, False, False],\n",
            "         [False, False, False,  ..., False, False, False],\n",
            "         [False, False, False,  ..., False, False, False]]], device='cuda:0')])}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 6: Create the scene graph by mapping objects to their relationships\n",
        "\n",
        "We create a list of objects by mapping the predicted bounding boxes to their corresponding class labels, and a list of relationships between these objects based on their overlap. We calculate the overlap between two objects by computing their intersection-over-union (IoU) score, and consider them to be related if their IoU score is above a certain threshold (in this case, 0.5)."
      ],
      "metadata": {
        "id": "VCFn168gheCV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_iou(box1, box2):\n",
        "    '''Compute the intersection over union of two set of boxes, each box is [x1,y1,x2,y2].\n",
        "    Args:\n",
        "      box1: (tensor) bounding boxes, sized (4,).\n",
        "      box2: (tensor) bounding boxes, sized (4,).\n",
        "    Return:\n",
        "      (tensor) iou.\n",
        "    '''\n",
        "    lt = np.zeros(2)\n",
        "    rb = np.zeros(2)    # get inter-area left_top/right_bottom\n",
        "    for i in range(2):\n",
        "        if box1[i] > box2[i]:\n",
        "            lt[i] = box1[i]\n",
        "        else:\n",
        "            lt[i] = box2[i]\n",
        "        if box1[i+2] < box2[i+2]:\n",
        "            rb[i] = box1[i+2]\n",
        "        else:\n",
        "            rb[i] = box2[i+2]\n",
        "    wh = rb-lt\n",
        "    wh[wh<0] = 0    # if no overlapping \n",
        "    inter = wh[0] * wh[1]\n",
        "    area1 = (box1[2]-box1[0]) * (box1[3]-box1[1])  \n",
        "    area2 = (box2[2]-box2[0]) * (box2[3]-box2[1])\n",
        "    iou = inter / (area1 + area2 - inter)          \n",
        "    return iou"
      ],
      "metadata": {
        "id": "UOOsVCsS53Lp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "objects = []\n",
        "relationships = []\n",
        "\n",
        "# Create objects from predicted boxes\n",
        "for i, box in enumerate(pred_boxes):\n",
        "    obj = {}\n",
        "    obj[\"class\"] = pred_classes[i]\n",
        "    obj[\"box\"] = box\n",
        "    objects.append(obj)\n",
        "\n",
        "# Create relationships between objects based on overlap\n",
        "for i, obj1 in enumerate(objects):\n",
        "    for j, obj2 in enumerate(objects):\n",
        "        if i == j:\n",
        "            continue\n",
        "        box1 = obj1[\"box\"]\n",
        "        box2 = obj2[\"box\"]\n",
        "        iou = calculate_iou(box1, box2)\n",
        "        if iou > 0.5:\n",
        "            relationships.append((i, j))\n"
      ],
      "metadata": {
        "id": "iVLxtSYc0I2z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 7: Visualize the scene graph using the detected bounding boxes and relationships\n",
        "\n",
        "Finally, we visualize the scene graph by drawing the predicted bounding boxes for the objects and the relationships between them using the \"Visualizer\" class from Detectron2. We create a \"Visualizer\" object, which takes the input image, the dataset metadata (in this case, the COCO dataset metadata), and a scale factor as arguments. We then draw the predicted bounding boxes for each object using the \"draw_box\" method of the \"Visualizer\" object, and draw the relationships between objects using the \"draw_line\" method. Finally, we get the output image using the \"get_image\" method of the \"Visualizer\" object, and save it to a file using the \"cv2.imwrite\" function.\n"
      ],
      "metadata": {
        "id": "8SuWeZCKhkNf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "v = Visualizer(im[:, :, ::-1], MetadataCatalog.get(cfg.DATASETS.TRAIN[0]), scale=1.2)\n",
        "for obj in objects:\n",
        "    box = BoxMode.convert(obj[\"box\"], BoxMode.XYXY_ABS, BoxMode.XYWH_ABS)\n",
        "    label = obj[\"class\"]\n",
        "    v.draw_box(box, edge_color=\"red\")\n",
        "    v.draw_text(label, box[:2])\n",
        "    print(label)\n",
        "for i, j in relationships:\n",
        "    v.draw_line(objects[i][\"box\"][:2], objects[j][\"box\"][:2], edge_color=\"blue\")\n",
        "output_image = v.output.get_image()[:, :, ::-1]\n",
        "cv2.imwrite(\"/content/output_image2.jpg\", output_image)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EIDhtMCQAwTp",
        "outputId": "a9202af2-2c12-438f-f31c-94cd0a987fe4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "62\n",
            "56\n",
            "68\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(objects)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xeIq83SNBauq",
        "outputId": "42f5d05a-9fa1-49ed-ff26-0ca57cc08750"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'class': 62, 'box': [463.26171875, 231.37152099609375, 519.5032958984375, 278.918212890625]}, {'class': 56, 'box': [295.2305908203125, 412.6859130859375, 382.38751220703125, 508.31414794921875]}, {'class': 68, 'box': [924.3395385742188, 341.42022705078125, 1000.0, 581.0679931640625]}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## FASTER RCNN AND NEURAL MOTIFS"
      ],
      "metadata": {
        "id": "4VI28db-J2bL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is an attempt at using [neural-motifs](https://github.com/rowanz/neural-motifs) to generate scene graphs. But apparently, neural motifs is not a python project therefore does not have a ```setup.py``` to build the repo. That's why [maskrcnn_benchmark](https://github.com/KaihuaTang/Scene-Graph-Benchmark.pytorch) is used."
      ],
      "metadata": {
        "id": "cEO-84HEjDgM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/rowanz/neural-motifs.git\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DzT3jHshOmpO",
        "outputId": "3cd47665-c456-4dce-d4d3-cb0d6a7b5f77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'neural-motifs'...\n",
            "remote: Enumerating objects: 269, done.\u001b[K\n",
            "remote: Total 269 (delta 0), reused 0 (delta 0), pack-reused 269\u001b[K\n",
            "Receiving objects: 100% (269/269), 546.08 KiB | 8.40 MiB/s, done.\n",
            "Resolving deltas: 100% (92/92), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "After downloading the repository, you need to add it to your Python path. You can do that by running the following command in the neural-motifs directory:"
      ],
      "metadata": {
        "id": "mn1UlDeWjkU7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!export PYTHONPATH=~/content/neural-motifs\n",
        "#!export PYTHONPATH:'$/env/python:/home/rowan/code/scene-graph'\n",
        "! echo $PYTHONPATH\n",
        "%env PYTHONPATH=/env/python/home/rowan/code/scene-graph\n",
        "! echo $PYTHONPATH"
      ],
      "metadata": {
        "id": "YhCgrJknO_it",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1511071-358a-4ed7-d586-c0e75d2c50d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\"/env/python/home/rowan/code/scene-graph\"\n",
            "env: PYTHONPATH=/env/python/home/rowan/code/scene-graph\n",
            "/env/python/home/rowan/code/scene-graph\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('/content/neural-motifs')"
      ],
      "metadata": {
        "id": "ZTFC7XSjD6qD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!echo $PYTHONPATH"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DW7rWveUG0iD",
        "outputId": "5d2e3b75-3ca9-4aa5-adcb-2c074cfca64e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/env/python/home/rowan/code/scene-graph\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/neural-motifs/\n",
        "#%cd /content/\n",
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uyiUKGw1Nhk6",
        "outputId": "d4ef5f27-22dd-4d9c-e54e-9422de8da361"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/neural-motifs\n",
            "/content/neural-motifs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install Cython\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VkyW0jv_O0MZ",
        "outputId": "3a00638e-aaef-4471-c451-3db7043cbf7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: Cython in /usr/local/lib/python3.8/dist-packages (0.29.33)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Attempt to run ```Makefile``` as mentioned in the [neural-motifs](https://github.com/rowanz/neural-motifs) repo."
      ],
      "metadata": {
        "id": "otCn4pHnjve9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install build-essential\n",
        "!make -f Makefile"
      ],
      "metadata": {
        "id": "3AyQa8BaNovy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -e /content/neural-motifs/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dK7PDzysHuzZ",
        "outputId": "e3f0e6ba-ffc2-400d-a64a-9520ac11519a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Obtaining file:///content/neural-motifs\n",
            "\u001b[31mERROR: file:///content/neural-motifs does not appear to be a Python project: neither 'setup.py' nor 'pyproject.toml' found.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hence, I fail to use neural-motifs as the relation detection model. Moving on to maskrcnn_benchmark."
      ],
      "metadata": {
        "id": "OrgcOy_cj9Vb"
      }
    }
  ]
}